{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8r210YMTTgom",
        "outputId": "d50f13d3-a0eb-4484-9bc2-f20e96086830"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "id": "fvdbacCbTaxP",
        "outputId": "ba0b25a4-3246-4fae-dfde-c6767e6388fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1695 files belonging to 4 classes.\n",
            "Found 502 files belonging to 4 classes.\n",
            "Found 246 files belonging to 4 classes.\n",
            "Classes: ['glioma', 'meningioma', 'no_tumor', 'pituitary']\n",
            "Saved: /drive/MyDrive/artifacts/class_indices.json\n",
            "Class counts: [564 358 335 438]\n",
            "Class weights: {0: 0.7211531115429481, 1: 1.1361183098050915, 2: 1.2141204624185755, 3: 0.9286081162333852}\n",
            "[CustomCNN] Trainable params: 1,012,644\n",
            "Epoch 1/15\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 5.50596, saving model to /drive/MyDrive/artifacts/best_CustomCNN.keras\n",
            "53/53 - 453s - 9s/step - accuracy: 0.6708 - loss: 0.8314 - val_accuracy: 0.3625 - val_loss: 5.5060 - learning_rate: 1.0000e-03\n",
            "Epoch 2/15\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2219181016.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;31m# 1) Custom CNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0mcustom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_custom_cnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m acc_custom, model_custom, ckpt_custom = train_model(\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;34m\"CustomCNN\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m )\n",
            "\u001b[0;32m/tmp/ipython-input-2219181016.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(name, model, train_ds, val_ds, test_ds, lr, epochs, patience, class_weights)\u001b[0m\n\u001b[1;32m    185\u001b[0m     ]\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m     history = model.fit(\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             ):\n\u001b[0;32m--> 220\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1689\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "import os, json, math, random, numpy as np, tensorflow as tf\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "tf.__version__\n",
        "\n",
        "# Reproducibility\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)\n",
        "\n",
        "# Paths\n",
        "ROOT = Path(\"/drive/MyDrive\")\n",
        "DATA_ROOT = ROOT / \"Tumour\"     # expects subfolders: train/ valid/ test\n",
        "ARTIFACTS = ROOT / \"artifacts\"\n",
        "ARTIFACTS.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Hyperparams (kept aligned with your original)\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 15\n",
        "PATIENCE = 4\n",
        "USE_CLASS_WEIGHTS = True\n",
        "FINE_TUNE_LAST_N_LAYERS = 50\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "# %% [data] Load splits from directories\n",
        "train_dir = DATA_ROOT / \"train\"\n",
        "val_dir   = DATA_ROOT / \"valid\"\n",
        "test_dir  = DATA_ROOT / \"test\"\n",
        "\n",
        "def make_ds(dir_path, shuffle, batch_size=BATCH_SIZE):\n",
        "    return tf.keras.utils.image_dataset_from_directory(\n",
        "        directory=str(dir_path),\n",
        "        labels=\"inferred\",\n",
        "        label_mode=\"int\",\n",
        "        image_size=(IMG_SIZE, IMG_SIZE),\n",
        "        interpolation=\"bilinear\",\n",
        "        shuffle=shuffle,\n",
        "        seed=SEED,\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "\n",
        "train_ds = make_ds(train_dir, shuffle=True)\n",
        "val_ds   = make_ds(val_dir,   shuffle=False)\n",
        "test_ds  = make_ds(test_dir,  shuffle=False)\n",
        "\n",
        "class_names = train_ds.class_names\n",
        "num_classes = len(class_names)\n",
        "print(\"Classes:\", class_names)\n",
        "\n",
        "# Persist class map (index -> name), same as your original\n",
        "with open(ARTIFACTS / \"class_indices.json\", \"w\") as f:\n",
        "    json.dump({i: c for i, c in enumerate(class_names)}, f, indent=2)\n",
        "print(\"Saved:\", ARTIFACTS / \"class_indices.json\")\n",
        "\n",
        "# Prefetch for speed\n",
        "def tune(ds, training=False):\n",
        "    if training:\n",
        "        ds = ds.shuffle(1000, seed=SEED, reshuffle_each_iteration=True)\n",
        "    return ds.prefetch(AUTOTUNE)\n",
        "\n",
        "train_ds = tune(train_ds, training=True)\n",
        "val_ds   = tune(val_ds)\n",
        "test_ds  = tune(test_ds)\n",
        "\n",
        "# %% [preprocessing & augmentation]\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Data augmentation (roughly mirrors: HFlip, Rotation(10°), RandomResizedCrop scale(0.9,1.0))\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.1),\n",
        "    # Zoom-in only (≈ crop then resize back up)\n",
        "    layers.RandomZoom(height_factor=(-0.1, 0.0), width_factor=(-0.1, 0.0)),\n",
        "])\n",
        "\n",
        "# ImageNet mean/std normalization (matches your torchvision.Normalize) for the CUSTOM CNN\n",
        "# Normalization takes variance (std^2)\n",
        "imagenet_norm = layers.Normalization(\n",
        "    mean=[0.485, 0.456, 0.406],\n",
        "    variance=[0.229**2, 0.224**2, 0.225**2],\n",
        "    name=\"imagenet_norm\"\n",
        ")\n",
        "\n",
        "# EfficientNetB0 in Keras has built-in rescaling & normalization inside the model,\n",
        "# so we DO NOT apply the above mean/std for the EfficientNet branch. We still rescale for the custom CNN.\n",
        "\n",
        "# %% [class weights]\n",
        "def compute_class_weights(dataset, num_classes):\n",
        "    counts = np.zeros(num_classes, dtype=np.int64)\n",
        "    for _, y in dataset.unbatch():\n",
        "        counts[int(y.numpy())] += 1\n",
        "    # Same idea: inverse frequency, normalized to average weight=1\n",
        "    w = 1.0 / np.clip(counts, 1, None)\n",
        "    w = w / w.sum() * num_classes\n",
        "    return {i: float(w[i]) for i in range(num_classes)}, counts\n",
        "\n",
        "class_weights, counts = (None, None)\n",
        "if USE_CLASS_WEIGHTS:\n",
        "    class_weights, counts = compute_class_weights(train_ds, num_classes)\n",
        "    print(\"Class counts:\", counts)\n",
        "    print(\"Class weights:\", class_weights)\n",
        "\n",
        "\n",
        "def build_custom_cnn(num_classes):\n",
        "    inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "    x = layers.Rescaling(1./255)(inputs)\n",
        "    x = data_augmentation(x)\n",
        "    x = imagenet_norm(x)  # match PyTorch normalization\n",
        "\n",
        "    # Conv blocks\n",
        "    def block(x, out_ch):\n",
        "        x = layers.Conv2D(out_ch, 3, padding=\"same\", use_bias=False)(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.ReLU()(x)\n",
        "        x = layers.MaxPooling2D()(x)\n",
        "        return x\n",
        "\n",
        "    x = block(x, 32)\n",
        "    x = block(x, 64)\n",
        "    x = block(x, 128)\n",
        "    x = block(x, 256)\n",
        "\n",
        "    # Extra conv + GAP\n",
        "    x = layers.Conv2D(256, 3, padding=\"same\", use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "    # Classifier\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    x = layers.Dense(128, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "    model = models.Model(inputs, outputs, name=\"CustomCNN\")\n",
        "    return model\n",
        "\n",
        "# EfficientNetB0 (frozen / fine-tune)\n",
        "def build_efficientnet_b0(num_classes, train_base=False, fine_tune_last_n=0, name=\"EffNetB0\"):\n",
        "    # NOTE: EfficientNetB0 in Keras includes a rescaling layer internally\n",
        "    base = tf.keras.applications.EfficientNetB0(\n",
        "        include_top=False, weights=\"imagenet\", pooling=\"avg\", input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
        "    )\n",
        "    base.trainable = train_base\n",
        "    if train_base and fine_tune_last_n > 0:\n",
        "        # Freeze all but the last N layers of the base model\n",
        "        for layer in base.layers[:-fine_tune_last_n]:\n",
        "            layer.trainable = False\n",
        "\n",
        "    inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "    # We still apply augmentation here; EfficientNet will handle its own normalization internally.\n",
        "    x = data_augmentation(inputs)\n",
        "    x = base(x, training=False)  # important for BatchNorm behavior during fine-tune warmup\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "    model = models.Model(inputs, outputs, name=name)\n",
        "    return model\n",
        "\n",
        "\n",
        "def count_trainable_params(model):\n",
        "    return int(np.sum([np.prod(v.shape) for v in model.trainable_weights]))\n",
        "\n",
        "def compile_model(model, lr=1e-3, wd=1e-4):\n",
        "    # AdamW is available in TF 2.11+; fallback to Adam if needed\n",
        "    try:\n",
        "        opt = tf.keras.optimizers.AdamW(learning_rate=lr, weight_decay=wd)\n",
        "    except Exception:\n",
        "        opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "    model.compile(\n",
        "        optimizer=opt,\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "def train_model(name, model, train_ds, val_ds, test_ds, lr=1e-3, epochs=EPOCHS, patience=PATIENCE,\n",
        "                class_weights=None):\n",
        "    compile_model(model, lr=lr, wd=1e-4)\n",
        "    print(f\"[{name}] Trainable params: {count_trainable_params(model):,}\")\n",
        "\n",
        "    ckpt_path = ARTIFACTS / f\"best_{name}.keras\"\n",
        "    callbacks = [\n",
        "        tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2, verbose=1),\n",
        "        tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=patience, restore_best_weights=True, verbose=1),\n",
        "        tf.keras.callbacks.ModelCheckpoint(filepath=str(ckpt_path), monitor=\"val_loss\", save_best_only=True, verbose=1)\n",
        "    ]\n",
        "\n",
        "    history = model.fit(\n",
        "        train_ds,\n",
        "        validation_data=val_ds,\n",
        "        epochs=epochs,\n",
        "        class_weight=class_weights,\n",
        "        verbose=2,\n",
        "        callbacks=callbacks\n",
        "    )\n",
        "\n",
        "    te_loss, te_acc = model.evaluate(test_ds, verbose=0)\n",
        "    print(f\"[{name}] TEST   loss={te_loss:.4f} acc={te_acc:.4f}\")\n",
        "\n",
        "    # Predictions for full report\n",
        "    y_true = []\n",
        "    y_prob = []\n",
        "    for x_batch, y_batch in test_ds:\n",
        "        y_true.extend(y_batch.numpy().tolist())\n",
        "        y_prob.extend(model.predict(x_batch, verbose=0).tolist())\n",
        "    y_true = np.array(y_true)\n",
        "    y_prob = np.array(y_prob)\n",
        "    y_pred = np.argmax(y_prob, axis=1)\n",
        "\n",
        "    print(f\"[{name}] REPORT\\n\" + classification_report(y_true, y_pred, target_names=class_names, digits=4))\n",
        "    print(f\"[{name}] CONFUSION\\n{confusion_matrix(y_true, y_pred)}\")\n",
        "\n",
        "    return te_acc, model, str(ckpt_path)\n",
        "\n",
        "# 1) Custom CNN\n",
        "custom = build_custom_cnn(num_classes)\n",
        "acc_custom, model_custom, ckpt_custom = train_model(\n",
        "    \"CustomCNN\", custom, train_ds, val_ds, test_ds, lr=1e-3, class_weights=class_weights\n",
        ")\n",
        "\n",
        "# 2) EfficientNetB0 (frozen base)\n",
        "eff_frozen = build_efficientnet_b0(num_classes, train_base=False, name=\"EffNetB0_Frozen\")\n",
        "acc_frozen, model_frozen, ckpt_frozen = train_model(\n",
        "    \"EffNetB0_Frozen\", eff_frozen, train_ds, val_ds, test_ds, lr=1e-3, class_weights=class_weights\n",
        ")\n",
        "\n",
        "# 3) EfficientNetB0 (fine-tune last N layers)\n",
        "eff_ft = build_efficientnet_b0(num_classes, train_base=True, fine_tune_last_n=FINE_TUNE_LAST_N_LAYERS, name=\"EffNetB0_FT\")\n",
        "acc_ft, model_ft, ckpt_ft = train_model(\n",
        "    \"EffNetB0_FT\", eff_ft, train_ds, val_ds, test_ds, lr=1e-4, class_weights=class_weights\n",
        ")\n",
        "\n",
        "# Pick best by test accuracy\n",
        "scores = [\n",
        "    (acc_custom, model_custom, \"custom_cnn\", ckpt_custom),\n",
        "    (acc_frozen, model_frozen, \"efficientnet_b0\", ckpt_frozen),\n",
        "    (acc_ft,     model_ft,     \"efficientnet_b0\", ckpt_ft),\n",
        "]\n",
        "best_acc, best_model, arch, best_ckpt = max(scores, key=lambda t: t[0])\n",
        "print(f\"[BEST] acc={best_acc:.4f} arch={arch}\")\n",
        "\n",
        "# Save a unified \"best\" export and the class map path (parallel to your .pt dict)\n",
        "best_export_path = ARTIFACTS / \"best_model\"\n",
        "best_model.save(best_export_path, include_optimizer=False)\n",
        "meta = {\n",
        "    \"model_name\": \"BEST\",\n",
        "    \"arch\": arch,\n",
        "    \"num_classes\": num_classes,\n",
        "    \"class_map_path\": str(ARTIFACTS / \"class_indices.json\"),\n",
        "    \"keras_checkpoint\": best_ckpt\n",
        "}\n",
        "with open(ARTIFACTS / \"best_model_meta.json\", \"w\") as f:\n",
        "    json.dump(meta, f, indent=2)\n",
        "print(\"Saved ->\", best_export_path)\n",
        "print(\"Saved ->\", ARTIFACTS / \"best_model_meta.json\")\n",
        "\n",
        "# %% [inference helper] Single-image predict (mirrors your predict_image)\n",
        "from PIL import Image\n",
        "\n",
        "def load_best(ckpt_dir=ARTIFACTS / \"best_model\"):\n",
        "    model = tf.keras.models.load_model(ckpt_dir)\n",
        "    with open(ARTIFACTS / \"class_indices.json\", \"r\") as f:\n",
        "        idx2cls = {int(k): v for k, v in json.load(f).items()}\n",
        "    return model, idx2cls\n",
        "\n",
        "def predict_image(img_path, model, idx2cls):\n",
        "    # The model already contains preprocessing/augmentation layers as defined above\n",
        "    img = tf.keras.utils.load_img(str(img_path), target_size=(IMG_SIZE, IMG_SIZE))\n",
        "    x = tf.keras.utils.img_to_array(img)\n",
        "    x = tf.expand_dims(x, axis=0)  # (1, H, W, 3)\n",
        "    probs = model.predict(x, verbose=0)[0]\n",
        "    pred_idx = int(np.argmax(probs))\n",
        "    return idx2cls[pred_idx], {idx2cls[i]: float(probs[i]) for i in range(len(probs))}\n",
        "\n",
        "# Example usage (optional; ensure you have at least one test image):\n",
        "# sample_class = class_names[0]\n",
        "# sample_path = next((test_dir / sample_class).glob(\"*.jpg\"))\n",
        "# model_loaded, idx2cls = load_best()\n",
        "# pred, probs = predict_image(sample_path, model_loaded, idx2cls)\n",
        "# print(\"Pred:\", pred)\n",
        "# print(\"Probs:\", probs)\n",
        "\n",
        "# %% [optional] Copy artifacts to Drive (uncomment in Colab)\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive', force_remount=True)\n",
        "# !mkdir -p \"/content/drive/MyDrive/BrainTumorArtifacts_TF\"\n",
        "# !cp -v /content/artifacts/* \"/content/drive/MyDrive/BrainTumorArtifacts_TF/\"\n",
        "# print(\"Artifacts copied to /content/drive/MyDrive/BrainTumorArtifacts_TF\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xpcgSmsJUgiS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}